{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Config:  {'batch_size': 32, 'learning_rate': 0.0001, 'warmup': 800, 'lr_decay': 'linear', 'weight_decay': 0, 'eval_frequency': 300, 'num_train_steps': 30000, 'num_eval_steps': 565}\n",
      "Model Config:  {'learn_pos_emb': True, 'tied_weights': False, 'embedding_dim': 64, 'transformer_dim': 64, 'transformer_hidden_dim': 128, 'head_dim': 32, 'num_head': 2, 'num_layers': 2, 'vocab_size': 512, 'max_seq_len': 4000, 'dropout_prob': 0.1, 'attention_dropout': 0.1, 'pooling_mode': 'MEAN', 'num_classes': 2}\n",
      "Loaded data//retrieval/retrieval.train.pickle... size=147086\n",
      "Loaded data//retrieval/retrieval.dev.pickle... size=18090\n",
      "Loaded data//retrieval/retrieval.test.pickle... size=17437\n"
     ]
    }
   ],
   "source": [
    "from data.Nystromformer.LRA.code import lra_config\n",
    "from data.Nystromformer.LRA.code.dataset import LRADataset\n",
    "#from Nystromformer.LRA.code.run_tasks import training_config\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "piaynTaskDataDir = \"data/\"\n",
    "piaynTaskModelDir = \"data/\"\n",
    "task = \"retrieval\"\n",
    "\n",
    "#get training config\n",
    "training_config = lra_config.config[task][\"training\"]\n",
    "\n",
    "#Check Train Config\n",
    "print('Training Config: ', training_config)\n",
    "\n",
    "#get pre-defined model config\n",
    "model_config = lra_config.config[task]['model']\n",
    "\n",
    "#Check model Config\n",
    "print('Model Config: ', model_config)\n",
    "\n",
    "#Get the dataset\n",
    "train_dataset = LRADataset(piaynTaskDataDir + f\"/{task}/{task}.train.pickle\", True)\n",
    "val_dataset = LRADataset(piaynTaskDataDir + f\"/{task}/{task}.dev.pickle\", False)\n",
    "test_dataset = LRADataset(piaynTaskDataDir + f\"/{task}/{task}.test.pickle\", False)\n",
    "\n",
    "#Create DataLoader iterators\n",
    "ds_iter = {\n",
    "    \"train\":enumerate(DataLoader(train_dataset, \n",
    "                                 batch_size = training_config[\"batch_size\"], \n",
    "                                 drop_last = True)),\n",
    "    \"dev\":enumerate(DataLoader(val_dataset, batch_size = 1, drop_last = True)),\n",
    "    \"test\":enumerate(DataLoader(test_dataset, batch_size = 1, drop_last = True)),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids_0 torch.Size([32, 4096])\n",
      "mask_0 torch.Size([32, 4096])\n",
      "input_ids_1 torch.Size([32, 4096])\n",
      "mask_1 torch.Size([32, 4096])\n",
      "label torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "#Check sizes of batches\n",
    "batch = next((ds_iter['train']))\n",
    "for k,v in batch[1].items():\n",
    "  print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PerceiverForSequenceClassification, PerceiverForMaskedLM\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PerceiverConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"audio_samples_per_frame\": 1920,\n",
      "  \"cross_attention_shape_for_attention\": \"kv\",\n",
      "  \"cross_attention_widening_factor\": 1,\n",
      "  \"d_latents\": 1280,\n",
      "  \"d_model\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"image_size\": 56,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"perceiver\",\n",
      "  \"num_blocks\": 1,\n",
      "  \"num_cross_attention_heads\": 8,\n",
      "  \"num_frames\": 16,\n",
      "  \"num_latents\": 256,\n",
      "  \"num_self_attends_per_block\": 26,\n",
      "  \"num_self_attention_heads\": 8,\n",
      "  \"output_shape\": [\n",
      "    1,\n",
      "    16,\n",
      "    224,\n",
      "    224\n",
      "  ],\n",
      "  \"qk_channels\": null,\n",
      "  \"samples_per_patch\": 16,\n",
      "  \"self_attention_widening_factor\": 1,\n",
      "  \"train_size\": [\n",
      "    368,\n",
      "    496\n",
      "  ],\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"use_query_residual\": true,\n",
      "  \"v_channels\": null,\n",
      "  \"vocab_size\": 262\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import PerceiverConfig\n",
    "#get default perceiver config\n",
    "configuration = PerceiverConfig()\n",
    "\n",
    "#Print Updated Perceiver Configuration\n",
    "print(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration.num_labels = 2\n",
    "configuration.num_self_attends_per_block = 3\n",
    "configuration.d_latents = 512\n",
    "configuration.d_model = 512\n",
    "configuration.max_position_embeddings = 4097\n",
    "configuration.num_cross_attention_heads = 4\n",
    "configuration.num_self_attention_heads = 4\n",
    "configuration.num_latents = 512\n",
    "configuration.vocab_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_cls(inp, mask, vocab_size):\n",
    "    batch_size = inp.size(0)\n",
    "    cls_id = ((vocab_size - 1) * torch.ones(batch_size, dtype=inp.dtype, device=inp.device))#.long()\n",
    "    cls_mask = torch.ones(batch_size, dtype=mask.dtype, device=mask.device)\n",
    "    # inp = torch.cat([cls_id[:, None], inp[:, :-1]], dim=-1)\n",
    "    # mask = torch.cat([cls_mask[:, None], mask[:, :-1]], dim=-1)\n",
    "    inp = torch.cat([cls_id[:, None], inp], dim=-1)\n",
    "    mask = torch.cat([cls_mask[:, None], mask], dim=-1)\n",
    "    return inp, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retrieval(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(Retrieval, self).__init__()\n",
    "        self.config = config\n",
    "        self.perceiver = PerceiverForMaskedLM(config = config)\n",
    "        self.linear1 = nn.Linear(512,128)\n",
    "        self.linear2 = nn.Linear(128,2)\n",
    "\n",
    "    def forward(self,input_ids_0, mask_0, input_ids_1, mask_1):\n",
    "        input_ids_0, mask_0 = append_cls(input_ids_0, mask_0, self.config.vocab_size)\n",
    "        input_ids_1, mask_1 = append_cls(input_ids_1, mask_1, self.config.vocab_size)\n",
    "        #print(input_ids_0.shape, mask_0.shape)\n",
    "        o1 = self.perceiver(inputs = input_ids_0, attention_mask = mask_0)\n",
    "        o1 = o1.logits[:,0,:]\n",
    "        o2 = self.perceiver(inputs = input_ids_1, attention_mask = mask_1)\n",
    "        o2 = o2.logits[:,0,:]\n",
    "        o3 = torch.cat([o1,o2,o1*o2,(o1 - o2)],axis = 1)\n",
    "        o4 = F.relu(self.linear1(o3))\n",
    "        o5 = self.linear2(o4)\n",
    "        return o5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = Retrieval(configuration)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters:  12218370 \n",
      "Trainable Parameters:  12218370\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in retriever.parameters())\n",
    "pytorch_total_params_Trainable = sum(p.numel() for p in retriever.parameters() if p.requires_grad)\n",
    "print('Total Parameters: ', pytorch_total_params, '\\nTrainable Parameters: ', pytorch_total_params_Trainable)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_0 = batch[1][\"input_ids_0\"].to(device)\n",
    "mask_0 = batch[1][\"mask_0\"].to(device)\n",
    "input_ids_1 = batch[1][\"input_ids_0\"].to(device)\n",
    "mask_1 = batch[1][\"mask_0\"].to(device)\n",
    "labels = batch[1][\"label\"].to(device)\n",
    "retriever = retriever.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4097]) torch.Size([32, 4097])\n"
     ]
    }
   ],
   "source": [
    "outputs = retriever(input_ids_0,mask_0,input_ids_1,mask_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(738,\n",
       " {'input_ids_0': tensor([[99, 40, 50,  ...,  0,  0,  0],\n",
       "          [99, 40, 50,  ...,  0,  0,  0],\n",
       "          [99, 40, 50,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [99, 40, 50,  ...,  0,  0,  0],\n",
       "          [99, 40, 50,  ...,  0,  0,  0],\n",
       "          [99, 40, 50,  ...,  0,  0,  0]]),\n",
       "  'mask_0': tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.]]),\n",
       "  'input_ids_1': tensor([[99, 40, 50,  ...,  0,  0,  0],\n",
       "          [99, 40, 50,  ...,  0,  0,  0],\n",
       "          [99, 35, 50,  ...,  0,  0,  0],\n",
       "          ...,\n",
       "          [99, 40, 50,  ...,  0,  0,  0],\n",
       "          [99, 40, 50,  ...,  0,  0,  0],\n",
       "          [99, 40, 50,  ...,  0,  0,  0]]),\n",
       "  'mask_1': tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [1., 1., 1.,  ..., 0., 0., 0.]]),\n",
       "  'label': tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 0, 1])})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " next(ds_iter['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arb881/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/arb881/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/arb881/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/arb881/.local/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ea6ac177774cda824fbedc5acaba40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6918203830718994, Accuracy: 0.53125\n",
      "Loss: 0.6933383941650391, Accuracy: 0.5\n",
      "Loss: 0.6946132779121399, Accuracy: 0.40625\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datasets import load_metric\n",
    "import pandas as pd\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "best_score = 0 \n",
    "prev_score = 0\n",
    "# maxPatience = 3\n",
    "# currentPatience = 0\n",
    "\n",
    "#steps = int(training_config[\"num_train_steps\"]/20000)\n",
    "steps = 5000\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "optimizer = AdamW(retriever.parameters(), \n",
    "                  lr = 0.5,\n",
    "                  betas = (0.9, 0.999), \n",
    "                  eps = 1e-6, \n",
    "                  weight_decay = training_config[\"weight_decay\"])\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer = optimizer,\n",
    "    max_lr = training_config[\"learning_rate\"],\n",
    "    #max_lr = 0.5,\n",
    "    pct_start = training_config[\"warmup\"] / training_config[\"num_train_steps\"],\n",
    "    #pct_start = training_config[\"warmup\"] / 5000,\n",
    "    anneal_strategy = training_config[\"lr_decay\"],\n",
    "    total_steps = training_config[\"num_train_steps\"],\n",
    "    #verbose=True\n",
    ")\n",
    "\n",
    "#amp_scaler = torch.cuda.amp.GradScaler() if model_config[\"mixed_precision\"] else None\n",
    "\n",
    "#initialize training summary\n",
    "trainingSummary = pd.DataFrame(columns=['step', 'train_acc', 'val_acc'])\n",
    "\n",
    "\n",
    "retriever.to(device)\n",
    "\n",
    "#initialize training accuracy metric\n",
    "train_accuracy = load_metric(\"accuracy\")\n",
    "#batch = next(ds_iter['train'])[1]\n",
    "\n",
    "for step in tqdm(range(30000)):  # Perform gradient updates for multiple steps\n",
    "    \n",
    "    #model.train()\n",
    "    retriever.train()\n",
    "    \n",
    "    #print(\"Step:\", step)\n",
    "    #for batch in tqdm(train_dataloader):\n",
    "    batch = next(ds_iter['train'])[1]\n",
    "\n",
    "    # get the inputs; \n",
    "    input_ids_0 = batch[\"input_ids_0\"].to(device)\n",
    "    mask_0 = batch[\"mask_0\"].to(device)\n",
    "    input_ids_1 = batch[\"input_ids_0\"].to(device)\n",
    "    mask_1 = batch[\"mask_0\"].to(device)\n",
    "    labels = batch[\"label\"].to(device)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = retriever(input_ids_0,mask_0,input_ids_1,mask_1)\n",
    "    loss = loss_fn(outputs,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # evaluate\n",
    "    predictions = outputs.argmax(-1).cpu().detach().numpy()\n",
    "    accuracy = accuracy_score(y_true=batch[\"label\"].numpy(), y_pred=predictions)\n",
    "    references = batch[\"label\"].numpy()\n",
    "    train_accuracy.add_batch(predictions=predictions, references=references)\n",
    "    \n",
    "    if (step+1)%50  == 0:\n",
    "        print(f\"Loss: {loss.item()}, Accuracy: {accuracy}\")\n",
    "\n",
    "    #delete intermediate variables to free up GPU space\n",
    "    del loss, outputs, input_ids_0, mask_0, labels, predictions, accuracy,input_ids_1,mask_1\n",
    "\n",
    "\n",
    "    #Every 1000 steps validate and save model\n",
    "    if (step+1)%training_config['eval_frequency']  == 0:\n",
    "    #if (step+1)%2  == 0:\n",
    "        #model.eval()\n",
    "        retriever.eval()\n",
    "        val_accuracy = load_metric(\"accuracy\")\n",
    "\n",
    "      #reset dev iterator\n",
    "        ds_iter['dev'] = enumerate(DataLoader(val_dataset, batch_size = 32, drop_last = True))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in tqdm(ds_iter['dev']):\n",
    "                input_ids_0 = batch[\"input_ids_0\"].to(device)\n",
    "                mask_0 = batch[\"mask_0\"].to(device)\n",
    "                input_ids_1 = batch[\"input_ids_0\"].to(device)\n",
    "                mask_1 = batch[\"mask_0\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "\n",
    "              # forward pass\n",
    "                logits = retriever(input_ids_0,mask_0,input_ids_1,mask_1)\n",
    "                predictions = logits.argmax(-1).cpu().detach().numpy()\n",
    "                references = batch[\"label\"].numpy()\n",
    "                val_accuracy.add_batch(predictions=predictions, references=references)\n",
    "\n",
    "          #delete intermediate variables to free up GPU space\n",
    "                del logits, input_ids_0, mask_0, input_ids_1, mask_1, labels, predictions, references\n",
    "      \n",
    "      #Compute val accuracy\n",
    "        final_val_score = val_accuracy.compute()['accuracy']\n",
    "        print(\"Validation Accuracy:\", final_val_score)\n",
    "\n",
    "        if final_val_score >= best_score:\n",
    "            best_score = final_val_score\n",
    "            torch.save(retriever.to('cpu').state_dict(), piaynTaskModelDir + '/trainedPerceiverClassifierToken'+'.pkl')\n",
    "            retriever.to(device)\n",
    "        else:\n",
    "            pass  \n",
    "\n",
    "#         if final_val_score <= prev_score:\n",
    "#             currentPatience += 1\n",
    "#             if currentPatience >= maxPatience:\n",
    "#                 print('Patience Limit reached! Stopping early!')\n",
    "#                 torch.save(retriever.to('cpu').state_dict(), piaynTaskModelDir + '/trainedPerceiverClassifierStep_' + str(step + 1) + 'Token' + '.pkl')\n",
    "#                 break  \n",
    "#         else:\n",
    "#             currentPatience = 0\n",
    "      \n",
    "      #Update prev_score\n",
    "        prev_score = final_val_score\n",
    "\n",
    "      #Compute training accuracy till now\n",
    "        final_train_score = train_accuracy.compute()['accuracy']\n",
    "\n",
    "      #Add to trainingSummary\n",
    "        trainingSummary.loc[len(trainingSummary.index)] = [step+1, final_train_score, final_val_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_metric\n",
    "\n",
    "retriever.to(device)\n",
    "retriever.eval()\n",
    "test_accuracy = load_metric(\"accuracy\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(ds_iter['test']):\n",
    "        # get the inputs; \n",
    "        input_ids_0 = batch[\"input_ids_0\"].to(device)\n",
    "        mask_0 = batch[\"mask_0\"].to(device)\n",
    "        input_ids_1 = batch[\"input_ids_0\"].to(device)\n",
    "        mask_1 = batch[\"mask_0\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        # forward pass\n",
    "        logits = retriever(input_ids_0,mask_0,input_ids_1,mask_1)\n",
    "        predictions = logits.argmax(-1).cpu().detach().numpy()\n",
    "        references = batch[\"label\"].numpy()\n",
    "        test_accuracy.add_batch(predictions=predictions, references=references)\n",
    "\n",
    "          #delete intermediate variables to free up GPU space\n",
    "        del logits, input_ids_0, mask_0, input_ids_1, mask_1, labels, predictions, references\n",
    "\n",
    "final_score = test_accuracy.compute()\n",
    "print(\"Accuracy on test set:\", final_score['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "def pooling(inp, mode):\n",
    "    if mode == \"CLS\":\n",
    "        pooled = inp[:, 0, :]\n",
    "    elif mode == \"MEAN\":\n",
    "        pooled = inp.mean(dim = 1)\n",
    "    else:\n",
    "        raise Exception()\n",
    "    return pooled\n",
    "\n",
    "def append_cls(inp, mask, vocab_size):\n",
    "    batch_size = inp.size(0)\n",
    "    cls_id = ((vocab_size - 1) * torch.ones(batch_size, dtype = torch.long, device = inp.device)).long()\n",
    "    cls_mask = torch.ones(batch_size, dtype = torch.float, device = mask.device)\n",
    "    inp = torch.cat([cls_id[:, None], inp[:, :-1]], dim = -1)\n",
    "    mask = torch.cat([cls_mask[:, None], mask[:, :-1]], dim = -1)\n",
    "    return inp, mask\n",
    "\n",
    "class SCHeadDual(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pooling_mode = \"CLS\"\n",
    "        self.mlpblock = nn.Sequential(\n",
    "            nn.Linear(128 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, inp_0, inp_1):\n",
    "        X_0 = pooling(inp_0, self.pooling_mode)\n",
    "        X_1 = pooling(inp_1, self.pooling_mode)\n",
    "        seq_score = self.mlpblock(torch.cat([X_0, X_1, X_0 * X_1, X_0 - X_1], dim = -1))\n",
    "        return seq_score\n",
    "\n",
    "class ModelForSCDual(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "\n",
    "#         self.enable_amp = config[\"mixed_precision\"]\n",
    "#         self.pooling_mode = config[\"pooling_mode\"]\n",
    "#         self.vocab_size = config[\"vocab_size\"]\n",
    "        self.model = model\n",
    "\n",
    "        self.seq_classifer = SCHeadDual()\n",
    "\n",
    "    def forward(self, input_ids_0, input_ids_1, mask_0, mask_1, label):\n",
    "\n",
    "        #with torch.cuda.amp.autocast(enabled = self.enable_amp):\n",
    "\n",
    "        \n",
    "        input_ids_0, mask_0 = append_cls(input_ids_0, mask_0, 128)\n",
    "        input_ids_1, mask_1 = append_cls(input_ids_1, mask_1, 128)\n",
    "\n",
    "        token_out_0 = self.model(input_ids_0, mask_0)\n",
    "        token_out_1 = self.model(input_ids_1, mask_1)\n",
    "        seq_scores = self.seq_classifer(token_out_0, token_out_1)\n",
    "\n",
    "        seq_loss = torch.nn.CrossEntropyLoss(reduction = \"none\")(seq_scores, label)\n",
    "        seq_accu = (seq_scores.argmax(dim = -1) == label).to(torch.float32)\n",
    "        outputs = {}\n",
    "        outputs[\"loss\"] = seq_loss\n",
    "        outputs[\"accu\"] = seq_accu\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
